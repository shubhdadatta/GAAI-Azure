{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "461743ad",
   "metadata": {},
   "source": [
    "# RAG Evaluation Using RAGAS\n",
    "\n",
    "## Introduction to Evaluation\n",
    "Evaluation in the context of Retrieval-Augmented Generation (RAG) systems involves assessing the performance of both the retrieval component (how well relevant documents are fetched from a knowledge base)\n",
    "and the generation component (how accurate, relevant, and coherent the generated responses are). A RAG system combines a retriever (e.g., a vector store like FAISS) with a language model (e.g., AzureChatOpenAI) to provide contextually informed responses, reducing issues like hallucinations (incorrect or fabricated information).\n",
    "\n",
    "## Why Do We Use Evaluation?\n",
    "- Evaluation is critical for the following reasons:\n",
    "- Quality Assurance: Ensures the RAG system delivers accurate, relevant, and trustworthy responses.\n",
    "- System Improvement: Identifies weaknesses in retrieval (e.g., irrelevant documents) or generation (e.g., unfaithful answers), guiding optimizations like better embeddings or prompt engineering.\n",
    "- Performance Monitoring: Quantifies system performance to track improvements or regressions over time.\n",
    "- Stakeholder Confidence: Provides metrics to demonstrate the system's reliability to stakeholders or end-users.\n",
    "\n",
    "### The RAGAS framework (Retrieval Augmented Generation Assessment) is used to evaluate RAG systems. It provides metrics like:\n",
    "- Faithfulness: Measures if the generated answer is factually grounded in the retrieved context.\n",
    "- Answer Relevancy: Assesses if the answer directly addresses the user's query.\n",
    "- Context Precision: Checks if the retrieved context contains relevant information with minimal noise.\n",
    "- Context Recall: Ensures all necessary information is retrieved (requires ground truth).\n",
    "\n",
    "This notebook sets up a RAG system using AzureChatOpenAI, AzureOpenAIEmbeddings, and FAISS, generates a synthetic test dataset, and evaluates the system using RAGAS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b676455",
   "metadata": {},
   "source": [
    "Loads environment variables (e.g., API keys) from a .env file for secure configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0d1f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MODEL_NAME = \"gpt-4.1-mini\"\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab08bef",
   "metadata": {},
   "source": [
    "\n",
    "Initializes AzureChatOpenAI for response generation and AzureOpenAIEmbeddings for creating document embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db718d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(azure_deployment=MODEL_NAME)\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings()\n",
    "\n",
    "dir_path = r\"data\"\n",
    "index_path = r\"index\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f667d3",
   "metadata": {},
   "source": [
    "## Document Loading\n",
    "This section loads PDF documents from a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45b7b308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded and split 902 document chunks.\n"
     ]
    }
   ],
   "source": [
    "def load_documents():\n",
    "    \"\"\"\n",
    "    Load PDF documents from the specified directory using PyMuPDFLoader.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of loaded documents.\n",
    "    \n",
    "    Raises:\n",
    "        FileNotFoundError: If the directory does not exist.\n",
    "        Exception: For other loading errors.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(dir_path):\n",
    "        raise FileNotFoundError(f\"Directory not found: {dir_path}\")\n",
    "    try:\n",
    "        loader = DirectoryLoader(dir_path, loader_cls=PyMuPDFLoader)\n",
    "        return loader.load()\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "def split_documents(documents):\n",
    "    \"\"\"\n",
    "    Split documents into smaller chunks using RecursiveCharacterTextSplitter.\n",
    "    \n",
    "    Args:\n",
    "        documents (list): List of documents to split.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of document chunks. Returns empty list if no documents.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not documents:\n",
    "            return []\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "        return text_splitter.split_documents(documents)\n",
    "    except Exception as e:\n",
    "        print(f\"Error splitting documents: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Load and split documents\n",
    "documents = load_documents()\n",
    "documents = split_documents(documents)\n",
    "print(f\"Loaded and split {len(documents)} document chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a0726e",
   "metadata": {},
   "source": [
    "## Vector Store Creation\n",
    "\n",
    "Now splits documents into chunks, and creates a FAISS vector store for retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e80f2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "def create_vectorstore(documents):\n",
    "    \"\"\"\n",
    "    Create and save a new FAISS vector store from documents.\n",
    "    \n",
    "    Args:\n",
    "        documents (list): List of document objects to convert to vectors.\n",
    "    \n",
    "    Returns:\n",
    "        None: If successful, else Exception.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if os.path.exists(os.path.join(index_path, \"index.faiss\")):\n",
    "            print(\"Vector store already exists, skipping creation.\")\n",
    "            return\n",
    "        os.makedirs(index_path, exist_ok=True)\n",
    "        vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "        save_vectorstore(vectorstore)\n",
    "        print(\"Vector store created successfully.\")\n",
    "    except Exception as e:\n",
    "        return e\n",
    "\n",
    "def save_vectorstore(vectorstore):\n",
    "    \"\"\"\n",
    "    Save the FAISS vector store to the specified path.\n",
    "    \n",
    "    Args:\n",
    "        vectorstore (FAISS): The vector store to save.\n",
    "    \n",
    "    Returns:\n",
    "        None: If successful, else Exception.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        vectorstore.save_local(index_path)\n",
    "    except Exception as e:\n",
    "        return e\n",
    "\n",
    "def load_vectorstore():\n",
    "    \"\"\"\n",
    "    Load an existing FAISS vector store.\n",
    "    \n",
    "    Returns:\n",
    "        FAISS: Loaded vector store, else Exception.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return FAISS.load_local(index_path, embeddings=embeddings, allow_dangerous_deserialization=True)\n",
    "    except Exception as e:\n",
    "        return e\n",
    "\n",
    "# Load or create vector store\n",
    "if os.path.exists(index_path) and any(os.listdir(index_path)):\n",
    "    vectorstore = load_vectorstore()\n",
    "    vectorstore_retriever = vectorstore.as_retriever(search_kwargs={'k': 5})\n",
    "    print(\"Vector store loaded successfully.\")\n",
    "else:\n",
    "    create_vectorstore(documents)\n",
    "    vectorstore = load_vectorstore()\n",
    "    vectorstore_retriever = vectorstore.as_retriever(search_kwargs={'k': 5})\n",
    "    print(\"Created and loaded new vector store.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b579f6",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "- Document Loading: Uses DirectoryLoader with PyMuPDFLoader to load PDFs from the data directory.\n",
    "- Document Splitting: Splits documents into chunks (500 characters, 200 overlap) for efficient retrieval.\n",
    "- Vector Store: Creates a FAISS index from document embeddings or loads an existing one from the index directory.\n",
    "- Retriever: Configures the vector store as a retriever, fetching the top 5 relevant documents for a query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a257d66b",
   "metadata": {},
   "source": [
    "## RAG Chain Setup\n",
    "This section defines a RAG chain that validates queries, retrieves relevant documents, and generates answers using the AzureChatOpenAI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec1c3a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Chain Response:\n",
      "- A supply chain involves a network of partners who collectively transform basic commodities into finished products valued by end customers.  \n",
      "- It encompasses the flow of materials from the initial source, through various stages of production, to the delivery of the final product to the customer.  \n",
      "- The supply chain also manages returns, which may include rejected materials, waste, or recyclable items like used products.  \n",
      "- The term \"supply network\" represents a more complex structure where organizations are interconnected and exchange flows bidirectionally, whereas \"supply chain\" denotes a simpler, sequential linkage of processes and entities.  \n",
      "- Supply chain activities and processes include planning, sourcing, making, delivering, and returning, which are repeated throughout the network.  \n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def validate_query(query):\n",
    "    \"\"\"\n",
    "    Validates a user's query by ensuring it is not empty and has at least 15 characters.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The input query.\n",
    "    \n",
    "    Returns:\n",
    "        str: The query if valid, or an error message if invalid.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not query:\n",
    "            return \"Query cannot be empty, enter a valid query.\"\n",
    "        elif len(query) < 15:\n",
    "            return \"Query is too short, enter a valid query.\"\n",
    "        else:\n",
    "            return query\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "def create_rag_chain(query, relevant_documents):\n",
    "    \"\"\"\n",
    "    Creates and executes a RAG chain to answer a query using retrieved documents.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The user query.\n",
    "        relevant_documents (list): List of retrieved document chunks.\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated response or an error message.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        prompt_template = \"\"\"\n",
    "        Only based on the provided documents, answer the question in points. Do not mention from which document the answer is derived.\n",
    "        Question: {query}\n",
    "        Documents: {docs}\n",
    "        Note: You are a supply chain assistant. If the query is not related to supply chain or the documents do not provide the necessary information, return \"Invalid Query\".\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "        valid_query = validate_query(query)\n",
    "        rag_chain = prompt | llm | StrOutputParser()\n",
    "        return rag_chain.invoke({\"query\": valid_query, \"docs\": relevant_documents})\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Test the RAG chain\n",
    "query = \"What is Supply Chain?\"\n",
    "relevant_documents = vectorstore_retriever.invoke(query)\n",
    "response = create_rag_chain(query, relevant_documents)\n",
    "print(\"RAG Chain Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccf2f98",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "- Query Validation: Ensures the query is non-empty and at least 15 characters long.\n",
    "- RAG Chain: Constructs a prompt that instructs the model to answer in bullet points, using only the retrieved documents, and to return \"Invalid Query\" if the query is unrelated to supply chain or unsupported by the documents.\n",
    "- Execution: Combines the prompt, AzureChatOpenAI model, and string output parser to generate a response.\n",
    "- Test: Runs a sample query to verify the RAG chain's functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc2bbe2",
   "metadata": {},
   "source": [
    "## Generating Synthetic Test Data with RAGAS\n",
    "To evaluate the RAG system, we need a test dataset with questions, answers, contexts, and ground truth. RAGAS's TestsetGenerator can create synthetic data from documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e18d305c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\code\\Langchain_Leaern\\Tradence\\RAG_Evaluation\\rag_temp_venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Applying CustomNodeFilter:   0%|          | 0/10 [00:00<?, ?it/s]       Node e1da785e-4086-4c2d-9bca-6c0273593aa4 does not have a summary. Skipping filtering.\n",
      "Node b897df9f-c458-4d58-b98c-c0c4d5f1bea7 does not have a summary. Skipping filtering.\n",
      "Node c79978a7-6cba-450a-a277-df4b26f6cbd1 does not have a summary. Skipping filtering.\n",
      "Node 16c30df2-be06-4249-a84d-26edeab66483 does not have a summary. Skipping filtering.\n",
      "Generating personas: 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]                                           \n",
      "Generating Scenarios: 100%|██████████| 3/3 [00:05<00:00,  1.93s/it]\n",
      "Generating Samples: 100%|██████████| 6/6 [00:49<00:00,  8.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 6 test cases.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "# Configure the test set generator\n",
    "testset_generator = TestsetGenerator.from_langchain(\n",
    "    llm=llm,\n",
    "    embedding_model=embeddings\n",
    ")\n",
    "\n",
    "# Randomly sample a subset of documents (e.g., 50 out of 902 chunks)\n",
    "sample_size = 10  # Adjust based on your needs\n",
    "random.seed(42)  # For reproducibility\n",
    "sampled_documents = random.sample(documents, min(sample_size, len(documents)))\n",
    "\n",
    "# Generate test dataset with reduced test_size\n",
    "testset = testset_generator.generate_with_langchain_docs(sampled_documents, 5)\n",
    "\n",
    "# Convert test dataset to evaluation format\n",
    "eval_data = {\n",
    "    \"question\": [],\n",
    "    \"answer\": [],\n",
    "    \"contexts\": [],\n",
    "    \"ground_truth\": []\n",
    "}\n",
    "\n",
    "for testcase in testset.samples:\n",
    "    relevant_docs = vectorstore_retriever.invoke(testcase.eval_sample.user_input)\n",
    "    answer = create_rag_chain(testcase.eval_sample.user_input, relevant_docs)\n",
    "    eval_data[\"question\"].append(testcase.eval_sample.user_input)\n",
    "    eval_data[\"answer\"].append(answer)\n",
    "    eval_data[\"contexts\"].append([doc.page_content for doc in relevant_docs])\n",
    "    eval_data[\"ground_truth\"].append(testcase.eval_sample.reference)\n",
    "\n",
    "print(f\"Generated {len(eval_data['question'])} test cases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221ee10c",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "- TestsetGenerator: Uses AzureChatOpenAI for generating and critiquing test cases, with AzureOpenAIEmbeddings for document embeddings.\n",
    "- Test Data Generation: Creates test cases with a mix of random samples\n",
    "- Evaluation Dataset: For each test case, retrieves relevant documents, generates an answer using the RAG chain, and collects the question, answer, contexts, and ground truth.\n",
    "- Output: Stores the data in a dictionary format suitable for RAGAS evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5536cdd4",
   "metadata": {},
   "source": [
    "## RAG Evaluation with RAGAS\n",
    "This section evaluates the RAG system using RAGAS metrics: faithfulness, answer relevancy, context precision, and context recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ac8b1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 24/24 [02:19<00:00,  5.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation Results:\n",
      "{'faithfulness': 0.8754, 'answer_relevancy': 0.9370, 'context_precision': 0.5889, 'context_recall': 0.8056}\n"
     ]
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall\n",
    "from datasets import Dataset\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "# Convert evaluation data to Hugging Face Dataset\n",
    "eval_dataset = Dataset.from_dict(eval_data)\n",
    "\n",
    "# Wrap AzureChatOpenAI for RAGAS compatibility\n",
    "evaluator_llm = LangchainLLMWrapper(llm)\n",
    "evaluator_embeddings = LangchainEmbeddingsWrapper(embeddings)\n",
    "\n",
    "# Run evaluation\n",
    "results = evaluate(\n",
    "    dataset=eval_dataset,\n",
    "    metrics=[\n",
    "        faithfulness,       # Checks if the answer is grounded in the context\n",
    "        answer_relevancy,   # Checks if the answer addresses the question\n",
    "        context_precision,  # Checks if retrieved context is relevant\n",
    "        context_recall      # Checks if all necessary information is retrieved\n",
    "    ],\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=evaluator_embeddings,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "# Print evaluation results\n",
    "print(\"RAGAS Evaluation Results:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ed496a",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "- Dataset Conversion: Converts the evaluation data into a Hugging Face Dataset for RAGAS.\n",
    "- LLM Wrapper: Wraps AzureChatOpenAI with LangchainLLMWrapper for compatibility with RAGAS.\n",
    "- Metrics: Evaluates the RAG system on:\n",
    "    - Faithfulness: Ensures answers are factually consistent with the context.\n",
    "    - Answer Relevancy: Measures how well answers address the query.\n",
    "    - Context Precision: Assesses the relevance of retrieved documents.\n",
    "    - Context Recall: Checks if all necessary information is retrieved (uses ground truth).\n",
    "- Results: Outputs scores (0 to 1) for each metric, where higher is better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_temp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
