{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2QLBDf4-O6E"
      },
      "source": [
        "# Multimodal Prompting with GPT-4 Vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DQhMOsGo84h6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import base64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CAngBvw_85aK"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_name=\"gpt4o\"\n",
        "azure_endpoint = os.environ['AZURE_OPENAI_ENDPOINT']\n",
        "api_version=os.environ['AZURE_OPENAI_API_VERSION']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_mmt3BME9JsB"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'generative-ai_image_covid_chart.png'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m IMAGE_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerative-ai_image_covid_chart.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m GPT4V_ENDPOINT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mazure_endpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mopenai/deployments/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/chat/completions?api-version=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapi_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m encoded_image \u001b[38;5;241m=\u001b[39m base64\u001b[38;5;241m.\u001b[39mb64encode(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mIMAGE_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mread())\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi-key\u001b[39m\u001b[38;5;124m\"\u001b[39m: GPT4V_KEY,\n\u001b[0;32m      9\u001b[0m }\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'generative-ai_image_covid_chart.png'"
          ]
        }
      ],
      "source": [
        "\n",
        "# Configuration\n",
        "GPT4V_KEY = os.environ['AZURE_OPENAI_API_KEY']\n",
        "IMAGE_PATH = \"generative-ai_image_covid_chart.png\"\n",
        "GPT4V_ENDPOINT = f\"{azure_endpoint}openai/deployments/{model_name}/chat/completions?api-version={api_version}\"\n",
        "encoded_image = base64.b64encode(open(IMAGE_PATH, 'rb').read()).decode('ascii')\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"api-key\": GPT4V_KEY,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvzhDZMX8kUS",
        "outputId": "0993814e-dce8-49f2-e943-fc44f5b247b8"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'encoded_image' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Payload for the request\u001b[39;00m\n\u001b[0;32m      2\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [ {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{ \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are an AI assistant that helps people find information.\u001b[39m\u001b[38;5;124m\"\u001b[39m}]},\n\u001b[0;32m      5\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m----> 6\u001b[0m                                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/jpeg;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mencoded_image\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[0;32m      7\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexplain this image\u001b[39m\u001b[38;5;124m\"\u001b[39m}]},\n\u001b[0;32m      8\u001b[0m   ],\n\u001b[0;32m      9\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.7\u001b[39m,\n\u001b[0;32m     10\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.95\u001b[39m,\n\u001b[0;32m     11\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m800\u001b[39m\n\u001b[0;32m     12\u001b[0m }\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Send request\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[1;31mNameError\u001b[0m: name 'encoded_image' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Payload for the request\n",
        "payload = {\n",
        "  \"messages\": [ {\"role\": \"system\", \"content\": [{ \"type\": \"text\",\n",
        "          \"text\": \"You are an AI assistant that helps people find information.\"}]},\n",
        "    {\"role\": \"user\",\"content\": [{\"type\": \"image_url\",\n",
        "                                 \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_image}\"}},\n",
        "        {\"type\": \"text\",\"text\": \"explain this image\"}]},\n",
        "  ],\n",
        "  \"temperature\": 0.7,\n",
        "  \"top_p\": 0.95,\n",
        "  \"max_tokens\": 800\n",
        "}\n",
        "\n",
        "# Send request\n",
        "try:\n",
        "    response = requests.post(GPT4V_ENDPOINT, headers=headers, json=payload)\n",
        "    response.raise_for_status()  # Will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
        "except requests.RequestException as e:\n",
        "    raise SystemExit(f\"Failed to make the request. Error: {e}\")\n",
        "\n",
        "# Handle the response as needed (e.g., print or process)\n",
        "print(response.json()['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7g12NsHB-Bd_"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'encoded_image' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[13], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Payload for the request\u001b[39;00m\n\u001b[0;32m      2\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [ {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{ \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are an AI assistant that helps people find information.\u001b[39m\u001b[38;5;124m\"\u001b[39m}]},\n\u001b[0;32m      5\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m----> 6\u001b[0m                                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/jpeg;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mencoded_image\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[0;32m      7\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextract the statistics from the image and provide as markdown table\u001b[39m\u001b[38;5;124m\"\u001b[39m}]},\n\u001b[0;32m      8\u001b[0m   ],\n\u001b[0;32m      9\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.7\u001b[39m,\n\u001b[0;32m     10\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.95\u001b[39m,\n\u001b[0;32m     11\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m800\u001b[39m\n\u001b[0;32m     12\u001b[0m }\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Send request\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[1;31mNameError\u001b[0m: name 'encoded_image' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Payload for the request\n",
        "payload = {\n",
        "  \"messages\": [ {\"role\": \"system\", \"content\": [{ \"type\": \"text\",\n",
        "          \"text\": \"You are an AI assistant that helps people find information.\"}]},\n",
        "    {\"role\": \"user\",\"content\": [{\"type\": \"image_url\",\n",
        "                                 \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_image}\"}},\n",
        "        {\"type\": \"text\",\"text\": \"extract the statistics from the image and provide as markdown table\"}]},\n",
        "  ],\n",
        "  \"temperature\": 0.7,\n",
        "  \"top_p\": 0.95,\n",
        "  \"max_tokens\": 800\n",
        "}\n",
        "\n",
        "# Send request\n",
        "try:\n",
        "    response = requests.post(GPT4V_ENDPOINT, headers=headers, json=payload)\n",
        "    response.raise_for_status()  # Will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
        "except requests.RequestException as e:\n",
        "    raise SystemExit(f\"Failed to make the request. Error: {e}\")\n",
        "\n",
        "# Handle the response as needed (e.g., print or process)\n",
        "print(response.json()['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtw9yI_Z-MQ7"
      },
      "source": [
        "## Thank You"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPWqFd6B14Wve9ZoJe6JP1l",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
