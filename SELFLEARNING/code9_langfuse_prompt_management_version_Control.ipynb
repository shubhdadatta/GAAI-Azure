{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "635ef627",
      "metadata": {
        "id": "635ef627"
      },
      "source": [
        "# Prompt Versioning, Testing & Tracing with **Langfuse**\n",
        "_A hands‑on guide for Generative AI Architects (local deployment)_\n",
        "\n",
        "---\n",
        "## 1  Why Langfuse?\n",
        "- **Prompt management** – track versions, diff, roll back.\n",
        "- **Prompt testing** – automated & human/LLM evaluations.\n",
        "- **Tracing** – token‑level observability.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d8e251c",
      "metadata": {
        "id": "8d8e251c"
      },
      "source": [
        "## 2  Spin up Langfuse locally\n",
        "```bash\n",
        "docker compose up -d\n",
        "open http://localhost:3000   # admin / admin\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "bNhbMddxY8Br",
      "metadata": {
        "id": "bNhbMddxY8Br"
      },
      "outputs": [],
      "source": [
        "!pip install langfuse --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NZMggQgNYqb7",
      "metadata": {
        "id": "NZMggQgNYqb7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-xxxxxxxxxxx\"\n",
        "#os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-xxxxxxxxxxxxxxxxxxxx\"\n",
        "#os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" #\"http://localhost:3000\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbde3fe3",
      "metadata": {
        "id": "dbde3fe3"
      },
      "source": [
        "## 3  Prompt Creation via Python SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "hW4Ak0INeVBC",
      "metadata": {
        "id": "hW4Ak0INeVBC"
      },
      "outputs": [],
      "source": [
        "from langfuse import Langfuse\n",
        "import os, textwrap\n",
        "\n",
        "\n",
        "#os.environ['AZURE_OPENAI_ENDPOINT'] = \"https://azure-openai-may2-25.openai.azure.com\"\n",
        "#os.environ['AZURE_OPENAI_API_KEY'] = \"xxxxxxxxxxxxxxxxx\"\n",
        "\n",
        "lf = Langfuse(public_key=os.getenv(\"LANGFUSE_PUBLIC_KEY\"),\n",
        "              secret_key=os.getenv(\"LANGFUSE_SECRET_KEY\"),\n",
        "              host=os.getenv(\"LANGFUSE_HOST\", \"http://localhost:3000\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "266aa176",
      "metadata": {},
      "outputs": [],
      "source": [
        "telcoprompt = lf.create_prompt(\n",
        "    name='telcogpt-app',\n",
        "    type='text',\n",
        "    prompt = \"you are an expert telecom engineer, anwer user question from telco point of view, here is the question {{question}}\",\n",
        "    labels=['production'],\n",
        "    config={\"model\":'gpt-4o-mini',\"temperature\":0.7,\"supported_language\":['en','fr']}\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "JJC6YwHZeWDS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJC6YwHZeWDS",
        "outputId": "dfff497e-dd4c-4bc8-ea6b-b491b73be8bf"
      },
      "outputs": [],
      "source": [
        "# Create a text prompt\n",
        "textprompt = lf.create_prompt(\n",
        "    name=\"movie-critic\",\n",
        "    type=\"text\",\n",
        "    prompt=\"As a {{criticlevel}} movie critic, do you like {{movie}}?\",\n",
        "    labels=[\"production\"],  # directly promote to production\n",
        "    config={\n",
        "        \"model\": \"gpt-4o\",\n",
        "        \"temperature\": 0.7,\n",
        "        \"supported_languages\": [\"en\", \"fr\"],\n",
        "    },  # optionally, add configs (e.g. model parameters or model tools) or tags\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "61c5d07b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: movie-critic Version: 1\n"
          ]
        }
      ],
      "source": [
        "print(\"Prompt:\", textprompt.name, \"Version:\", textprompt.version)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6Z1YdBwPe2rH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Z1YdBwPe2rH",
        "outputId": "c5a5cd1b-0fcb-4c39-c3fa-65ae252f8774"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: As a {{criticlevel}} movie critic, do you like {{movie}}?\n"
          ]
        }
      ],
      "source": [
        "print(\"Prompt:\", textprompt.prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "s4BFzWGQemPN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4BFzWGQemPN",
        "outputId": "6f7a5516-01c0-49e4-d2af-49dc3e6f92c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: movie-critic-chat Version: 1\n"
          ]
        }
      ],
      "source": [
        "# Create a chat prompt\n",
        "chatprompt = lf.create_prompt(\n",
        "    name=\"movie-critic-chat\",\n",
        "    type=\"chat\",\n",
        "    prompt=[\n",
        "      { \"role\": \"system\", \"content\": \"You are an {{criticlevel}} movie critic\" },\n",
        "      { \"role\": \"user\", \"content\": \"Do you like {{movie}}?\" },\n",
        "    ],\n",
        "    labels=[\"production\"],  # directly promote to production\n",
        "    config={\n",
        "        \"model\": \"gpt-4o\",\n",
        "        \"temperature\": 0.7,\n",
        "        \"supported_languages\": [\"en\", \"fr\"],\n",
        "    },  # optionally, add configs (e.g. model parameters or model tools) or tags\n",
        ")\n",
        "\n",
        "print(\"Prompt:\", chatprompt.name, \"Version:\", chatprompt.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "kbQ67XkEfAq0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbQ67XkEfAq0",
        "outputId": "d859c72c-055c-4295-d8a8-0041996ee639"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: [{'role': 'system', 'content': 'You are an {{criticlevel}} movie critic'}, {'role': 'user', 'content': 'Do you like {{movie}}?'}]\n"
          ]
        }
      ],
      "source": [
        "print(\"Prompt:\", chatprompt.prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "37e3982d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37e3982d",
        "outputId": "48b12b17-9d70-4489-cfd1-8146176ce881"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt Name: project-plan-generator Version: 2\n"
          ]
        }
      ],
      "source": [
        "prompt_text = textwrap.dedent(\"\\nYou are an elite **Project Management Advisor** tasked with producing a _comprehensive_ delivery plan.\\n\\n**Project\\u00a0Name:** {{project_name}}  \\n**Project\\u00a0Scope\\u00a0(1\\u00a0sentence):** {{project_scope}}\\n\\n---\\n\\n## Required Output (markdown):\\n\\n1. **Executive Summary** \\u2013 3\\u00a0bullet points.  \\n2. **Detailed Work\\u2011breakdown Structure (WBS)**  \\n   - Use a markdown table with columns: *Work\\u2011stream*, *Tasks*, *Owner*, *Start*, *End*.  \\n   - At least 6\\u00a0work\\u2011streams, each with 3\\u20115\\u00a0tasks.\\n3. **Milestones** \\u2013 list every high\\u2011level milestone in the format `YYYY\\u2011MM\\u2011DD\\u00a0\\u2013\\u00a0Milestone name`.  \\n4. **Risk Register** \\u2013 another markdown table with *Risk*, *Impact (1\\u20115)*, *Probability\\u00a0(%) *, *Mitigation*.  \\n5. **Stakeholder\\u00a0Map** \\u2013 classify the following stakeholders ({{stakeholder_list}}) under *Manage\\u00a0Closely*, *Keep\\u00a0Satisfied*, *Keep\\u00a0Informed*, *Monitor*.  \\n6. **Budget\\u00a0Summary** \\u2013 break down the total budget **{{budget}}** into at least 4\\u00a0cost lines (**%** of total).\\n7. **Timeline Visualization** \\u2013 an ASCII Gantt chart up to **deadline\\u00a0{{deadline}}**.\\n8. End with an encouraging emoji.\\n\\n**Rules**\\n\\n- Sections must appear in order above.  \\n- Do **not** hallucinate dates beyond the supplied deadline.  \\n- Keep answer under 2000\\u00a0tokens.\\n\")\n",
        "\n",
        "prompt_v1 = lf.create_prompt(\n",
        "    name=\"project-plan-generator\",\n",
        "    prompt=prompt_text,\n",
        "    config={\"model\":\"gpt-4o-mini\",\"temperature\":0.2},\n",
        "    labels=[\"production\"],\n",
        "\n",
        ")\n",
        "\n",
        "print(\"Prompt Name:\", prompt_v1.name, \"Version:\", prompt_v1.version)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "xsmRV02CYJtx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsmRV02CYJtx",
        "outputId": "ecfc85f6-3a68-4b2b-934b-fbb270d4bf1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "You are an elite **Project Management Advisor** tasked with producing a _comprehensive_ delivery plan.\n",
            "\n",
            "**Project Name:** {{project_name}}  \n",
            "**Project Scope (1 sentence):** {{project_scope}}\n",
            "\n",
            "---\n",
            "\n",
            "## Required Output (markdown):\n",
            "\n",
            "1. **Executive Summary** – 3 bullet points.  \n",
            "2. **Detailed Work‑breakdown Structure (WBS)**  \n",
            "   - Use a markdown table with columns: *Work‑stream*, *Tasks*, *Owner*, *Start*, *End*.  \n",
            "   - At least 6 work‑streams, each with 3‑5 tasks.\n",
            "3. **Milestones** – list every high‑level milestone in the format `YYYY‑MM‑DD – Milestone name`.  \n",
            "4. **Risk Register** – another markdown table with *Risk*, *Impact (1‑5)*, *Probability (%) *, *Mitigation*.  \n",
            "5. **Stakeholder Map** – classify the following stakeholders ({{stakeholder_list}}) under *Manage Closely*, *Keep Satisfied*, *Keep Informed*, *Monitor*.  \n",
            "6. **Budget Summary** – break down the total budget **{{budget}}** into at least 4 cost lines (**%** of total).\n",
            "7. **Timeline Visualization** – an ASCII Gantt chart up to **deadline {{deadline}}**.\n",
            "8. End with an encouraging emoji.\n",
            "\n",
            "**Rules**\n",
            "\n",
            "- Sections must appear in order above.  \n",
            "- Do **not** hallucinate dates beyond the supplied deadline.  \n",
            "- Keep answer under 2000 tokens.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(prompt_v1.prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "r8ZTm59XfyZc",
      "metadata": {
        "id": "r8ZTm59XfyZc"
      },
      "source": [
        "## Fetch prompt from Langfuse Prompt Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ur9NN1a-fxqb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur9NN1a-fxqb",
        "outputId": "f9e79d0e-b3ad-4a4d-8faf-267805d62e83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "You are an elite **Project Management Advisor** tasked with producing a _comprehensive_ delivery plan.\n",
            "\n",
            "**Project Name:** {{project_name}}  \n",
            "**Project Scope (1 sentence):** {{project_scope}}\n",
            "\n",
            "---\n",
            "\n",
            "## Required Output (markdown):\n",
            "\n",
            "1. **Executive Summary** – 3 bullet points.  \n",
            "2. **Detailed Work‑breakdown Structure (WBS)**  \n",
            "   - Use a markdown table with columns: *Work‑stream*, *Tasks*, *Owner*, *Start*, *End*.  \n",
            "   - At least 6 work‑streams, each with 3‑5 tasks.\n",
            "3. **Milestones** – list every high‑level milestone in the format `YYYY‑MM‑DD – Milestone name`.  \n",
            "4. **Risk Register** – another markdown table with *Risk*, *Impact (1‑5)*, *Probability (%) *, *Mitigation*.  \n",
            "5. **Stakeholder Map** – classify the following stakeholders ({{stakeholder_list}}) under *Manage Closely*, *Keep Satisfied*, *Keep Informed*, *Monitor*.  \n",
            "6. **Budget Summary** – break down the total budget **{{budget}}** into at least 4 cost lines (**%** of total).\n",
            "7. **Timeline Visualization** – an ASCII Gantt chart up to **deadline {{deadline}}**.\n",
            "8. End with an encouraging emoji.\n",
            "\n",
            "**Rules**\n",
            "\n",
            "- Sections must appear in order above.  \n",
            "- Do **not** hallucinate dates beyond the supplied deadline.  \n",
            "- Keep answer under 2000 tokens.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = lf.get_prompt(\"project-plan-generator\")\n",
        "print(prompt.prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "JS_E9scwgAEo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS_E9scwgAEo",
        "outputId": "861de77e-2d3b-4cc6-9c6d-721bdca67e30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['project_name', 'project_scope', 'stakeholder_list', 'budget', 'deadline']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt.variables"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "026cae80",
      "metadata": {
        "id": "026cae80"
      },
      "source": [
        "## 4  Generate Plan using OpenAI SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ybeFHWyAgPQU",
      "metadata": {
        "id": "ybeFHWyAgPQU"
      },
      "outputs": [],
      "source": [
        "from langfuse.openai import AzureOpenAI\n",
        "client = AzureOpenAI(api_version=\"2024-12-01-preview\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3dfe0acd",
      "metadata": {
        "id": "3dfe0acd"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_plan(vars):\n",
        "    filled = prompt.compile(**vars)\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"myllm\",\n",
        "        messages=[{\"role\":\"system\",\"content\":\"You are an expert project‑management advisor.\"},\n",
        "                  {\"role\":\"user\",\"content\":filled}],\n",
        "        temperature=0.2\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "erLEwY_xg-2o",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erLEwY_xg-2o",
        "outputId": "9323497f-5266-4c5c-e2a2-c69ee506b515"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# AI Platform Overhaul Delivery Plan\n",
            "\n",
            "## Executive Summary\n",
            "- The project aims to completely rebuild the machine learning pipeline to effectively support Generative AI workloads.\n",
            "- Key deliverables include enhanced data ingestion, model training, deployment capabilities, and performance monitoring.\n",
            "- Successful completion will position the organization as a leader in AI capabilities, driving innovation and competitive advantage.\n",
            "\n",
            "## Detailed Work-breakdown Structure (WBS)\n",
            "\n",
            "| Work‑stream           ...\n"
          ]
        }
      ],
      "source": [
        "sample = generate_plan(dict(\n",
        "    project_name=\"AI Platform Overhaul\",\n",
        "    project_scope=\"Rebuild the ML pipeline end‑to‑end to support GenAI workloads.\",\n",
        "    deadline=\"2025-10-01\",\n",
        "    stakeholder_list=\"CTO, Head of Data, Product Manager, Cloud Ops Lead\",\n",
        "    budget=\"$500,000\"\n",
        "))\n",
        "\n",
        "print(sample[:500], \"...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "E3cCZPfCu5qH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3cCZPfCu5qH",
        "outputId": "8105cb46-4cf0-48ce-d801-89df27b5cd57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current version: 1\n"
          ]
        }
      ],
      "source": [
        "current = lf.get_prompt(\n",
        "    name   = \"project-plan-generator\",   # your prompt name\n",
        ")\n",
        "\n",
        "print(f\"Current version: {current.version}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "Izv9QgECylC8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Izv9QgECylC8",
        "outputId": "49b5961d-2f09-47f8-f55e-cc16b5b84b2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created version 3 (name project-plan-generator)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# **Create a new version** (safe / preferred)\n",
        "new_text = textwrap.dedent(current.prompt) + \"\\n\\n9. **Success Criteria** – list 3 KPIs.\"\n",
        "\n",
        "prompt_v_next = lf.create_prompt(\n",
        "    name   = current.name,          # same name auto‑increments the version\n",
        "    prompt = new_text,              # the modified body\n",
        "    config = current.config,        # keep model + temperature the same\n",
        "    labels = [\"candidate\"],         # start as 'candidate' until tests pass\n",
        ")\n",
        "\n",
        "print(f\"Created version {prompt_v_next.version} (name {prompt_v_next.name})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fec751f0",
      "metadata": {
        "id": "fec751f0"
      },
      "source": [
        "## 5  Best Practices Checklist"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sTEFJnqfi3PR",
      "metadata": {
        "id": "sTEFJnqfi3PR"
      },
      "source": [
        "|  Area           |  Guideline                                                       |\n",
        "| --------------- | ---------------------------------------------------------------- |\n",
        "|  Observability  |  Log **every** prod call (no sampling) for full forensic traces. |\n",
        "|  PII            | Hash sensitive text or set `metadata={\"pii\":True}` for masking.  |\n",
        "|  Cost           | Tighten retention in prod, use read‑only ClickHouse in staging.  |\n",
        "|  SemVer         | Use semantic prompt versions (`1.3.0`) or Git SHA in `comment=`. |\n",
        "|  Rollback       | Keep `production-previous` label ready for instant rollback.     |\n",
        "|         |                                                                  |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A2-suLIui3k0",
      "metadata": {
        "id": "A2-suLIui3k0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "10f816eb",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['name'], template='hi my name is {{name}} how are you', template_format='mustache')"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp = \"\"\"hi my name is {{name}} how are you\"\"\"\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "prompt = PromptTemplate.from_template(temp,template_format='mustache')\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edeacbab",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gen-ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
